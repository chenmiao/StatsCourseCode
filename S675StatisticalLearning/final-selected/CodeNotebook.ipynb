{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=load_svmlight_file(\"C:\\\\Users\\\\Miao\\\\Desktop\\\\Courses\\\\S675 Statistical Learning\\\\final\\\\corpus.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<593x204562 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6384862 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess doc_word matrix (data[0]), remove words that occur in fewer than 10 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-263-14ff2437bd5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mselected_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Miao\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mgetcol\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mCSR\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_row_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Miao\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[1;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[0;32m    422\u001b[0m         indptr, indices, data = get_csr_submatrix(M, N,\n\u001b[0;32m    423\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 int(i0), int(i1), int(j0), int(j1))\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mj0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###this tries to prune the raw doc_word matrix by removing words occuring in fewere than 10 docs\n",
    "###but I aborted this program because it's taking too long, after running for 6 hours; there are 204562 columns to loop through.\n",
    "ncols=data[0].shape[1]  #num of columns, i.e. num of words\n",
    "selected_cols=[]\n",
    "\n",
    "for i in range(ncols):\n",
    "    if len(data[0].getcol(i).nonzero()[0])>10:\n",
    "        selected_cols.append(i)\n",
    "\n",
    "selected_data=data[0][:, selected_cols]\n",
    "selected_data.shape\n",
    "###the pruned matrix will be the basis for calculating co-occurrence matrix, but since we aborted this step\n",
    "#for co-occurrence, we just calcualte cooccurrence of specific words, instead of the whole co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 14,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 28,\n",
       " 30,\n",
       " 35,\n",
       " 37,\n",
       " 38,\n",
       " 45,\n",
       " 48,\n",
       " 49,\n",
       " 53,\n",
       " 55,\n",
       " 60,\n",
       " 68,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 76,\n",
       " 78,\n",
       " 81,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 91,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 103,\n",
       " 114,\n",
       " 115,\n",
       " 118,\n",
       " 119,\n",
       " 121,\n",
       " 124,\n",
       " 125,\n",
       " 128,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 140,\n",
       " 142,\n",
       " 144,\n",
       " 146,\n",
       " 147,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 157,\n",
       " 158,\n",
       " 165,\n",
       " 166,\n",
       " 168,\n",
       " 170,\n",
       " 174,\n",
       " 181,\n",
       " 183,\n",
       " 184,\n",
       " 186,\n",
       " 187,\n",
       " 190,\n",
       " 192,\n",
       " 193,\n",
       " 196,\n",
       " 198,\n",
       " 199,\n",
       " 201,\n",
       " 203,\n",
       " 215,\n",
       " 216,\n",
       " 218,\n",
       " 221,\n",
       " 226,\n",
       " 228,\n",
       " 229,\n",
       " 232,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 249,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 256,\n",
       " 258,\n",
       " 262,\n",
       " 264,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 275,\n",
       " 276,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 287,\n",
       " 290,\n",
       " 291,\n",
       " 293,\n",
       " 295,\n",
       " 296,\n",
       " 310,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 321,\n",
       " 323,\n",
       " 324,\n",
       " 326,\n",
       " 329,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 344,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 357,\n",
       " 360,\n",
       " 365,\n",
       " 366,\n",
       " 369,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 377,\n",
       " 384,\n",
       " 388,\n",
       " 390,\n",
       " 391,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 404,\n",
       " 407,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 419,\n",
       " 421,\n",
       " 422,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 434,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 444,\n",
       " 446,\n",
       " 447,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 459,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 472,\n",
       " 473,\n",
       " 477,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 488,\n",
       " 496,\n",
       " 501,\n",
       " 505,\n",
       " 508,\n",
       " 510,\n",
       " 511,\n",
       " 517,\n",
       " 519,\n",
       " 523,\n",
       " 525,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 541,\n",
       " 546,\n",
       " 547,\n",
       " 553,\n",
       " 557,\n",
       " 561,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 581,\n",
       " 584,\n",
       " 585,\n",
       " 587,\n",
       " 588,\n",
       " 595,\n",
       " 598,\n",
       " 599,\n",
       " 601,\n",
       " 602,\n",
       " 604,\n",
       " 605,\n",
       " 607,\n",
       " 608,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 621,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 629,\n",
       " 631,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 652,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 661,\n",
       " 665,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 673,\n",
       " 677,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 685,\n",
       " 691,\n",
       " 693,\n",
       " 696,\n",
       " 700,\n",
       " 701,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 708,\n",
       " 709,\n",
       " 712,\n",
       " 718,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 726,\n",
       " 728,\n",
       " 729,\n",
       " 732,\n",
       " 735,\n",
       " 737,\n",
       " 740,\n",
       " 742,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 748,\n",
       " 750,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 758,\n",
       " 760,\n",
       " 761,\n",
       " 764,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 777,\n",
       " 781,\n",
       " 783,\n",
       " 784,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 796,\n",
       " 797,\n",
       " 803,\n",
       " 804,\n",
       " 807,\n",
       " 809,\n",
       " 810,\n",
       " 812,\n",
       " 813,\n",
       " 817,\n",
       " 820,\n",
       " 823,\n",
       " 824,\n",
       " 829,\n",
       " 832,\n",
       " 834,\n",
       " 836,\n",
       " 837,\n",
       " 845,\n",
       " 846,\n",
       " 858,\n",
       " 866,\n",
       " 882,\n",
       " 889,\n",
       " 890,\n",
       " 892,\n",
       " 895,\n",
       " 899,\n",
       " 905,\n",
       " 907,\n",
       " 908,\n",
       " 914,\n",
       " 917,\n",
       " 918,\n",
       " 921,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 931,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 948,\n",
       " 949,\n",
       " 951,\n",
       " 952,\n",
       " 955,\n",
       " 959,\n",
       " 960,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 969,\n",
       " 971,\n",
       " 972,\n",
       " 974,\n",
       " 977,\n",
       " 981,\n",
       " 983,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 997,\n",
       " 1001,\n",
       " 1008,\n",
       " 1012,\n",
       " 1013,\n",
       " 1017,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1022,\n",
       " 1028,\n",
       " 1029,\n",
       " 1031,\n",
       " 1036,\n",
       " 1038,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1050,\n",
       " 1052,\n",
       " 1053,\n",
       " 1054,\n",
       " 1055,\n",
       " 1062,\n",
       " 1064,\n",
       " 1065,\n",
       " 1068,\n",
       " 1071,\n",
       " 1073,\n",
       " 1076,\n",
       " 1077,\n",
       " 1078,\n",
       " 1079,\n",
       " 1080,\n",
       " 1081,\n",
       " 1086,\n",
       " 1089,\n",
       " 1090,\n",
       " 1099,\n",
       " 1100,\n",
       " 1102,\n",
       " 1103,\n",
       " 1104,\n",
       " 1106,\n",
       " 1110,\n",
       " 1111,\n",
       " 1112,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1125,\n",
       " 1126,\n",
       " 1129,\n",
       " 1130,\n",
       " 1133,\n",
       " 1136,\n",
       " 1138,\n",
       " 1140,\n",
       " 1141,\n",
       " 1142,\n",
       " 1143,\n",
       " 1144,\n",
       " 1148,\n",
       " 1152,\n",
       " 1153,\n",
       " 1157,\n",
       " 1159,\n",
       " 1162,\n",
       " 1163,\n",
       " 1164,\n",
       " 1165,\n",
       " 1167,\n",
       " 1169,\n",
       " 1174,\n",
       " 1176,\n",
       " 1177,\n",
       " 1179,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1184,\n",
       " 1185,\n",
       " 1186,\n",
       " 1188,\n",
       " 1191,\n",
       " 1192,\n",
       " 1193,\n",
       " 1194,\n",
       " 1196,\n",
       " 1200,\n",
       " 1201,\n",
       " 1202,\n",
       " 1203,\n",
       " 1205,\n",
       " 1211,\n",
       " 1216,\n",
       " 1218,\n",
       " 1220,\n",
       " 1221,\n",
       " 1222,\n",
       " 1223,\n",
       " 1224,\n",
       " 1225,\n",
       " 1226,\n",
       " 1228,\n",
       " 1232,\n",
       " 1233,\n",
       " 1237,\n",
       " 1240,\n",
       " 1241,\n",
       " 1242,\n",
       " 1243,\n",
       " 1244,\n",
       " 1246,\n",
       " 1247,\n",
       " 1248,\n",
       " 1249,\n",
       " 1250,\n",
       " 1252,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1257,\n",
       " 1258,\n",
       " 1261,\n",
       " 1267,\n",
       " 1276,\n",
       " 1280,\n",
       " 1285,\n",
       " 1286,\n",
       " 1309,\n",
       " 1310,\n",
       " 1318,\n",
       " 1320,\n",
       " 1323,\n",
       " 1326,\n",
       " 1327,\n",
       " 1328,\n",
       " 1338,\n",
       " 1339,\n",
       " 1345,\n",
       " 1353,\n",
       " 1362,\n",
       " 1363,\n",
       " 1365,\n",
       " 1366,\n",
       " 1368,\n",
       " 1373,\n",
       " 1377,\n",
       " 1378,\n",
       " 1379,\n",
       " 1383,\n",
       " 1387,\n",
       " 1388,\n",
       " 1389,\n",
       " 1390,\n",
       " 1391,\n",
       " 1392,\n",
       " 1396,\n",
       " 1397,\n",
       " 1398,\n",
       " 1399,\n",
       " 1401,\n",
       " 1406,\n",
       " 1411,\n",
       " 1422,\n",
       " 1425,\n",
       " 1433,\n",
       " 1434,\n",
       " 1436,\n",
       " 1439,\n",
       " 1441,\n",
       " 1451,\n",
       " 1452,\n",
       " 1453,\n",
       " 1454,\n",
       " 1456,\n",
       " 1457,\n",
       " 1459,\n",
       " 1463,\n",
       " 1468,\n",
       " 1471,\n",
       " 1475,\n",
       " 1484,\n",
       " 1485,\n",
       " 1487,\n",
       " 1488,\n",
       " 1489,\n",
       " 1490,\n",
       " 1491,\n",
       " 1492,\n",
       " 1494,\n",
       " 1495,\n",
       " 1496,\n",
       " 1505,\n",
       " 1506,\n",
       " 1515,\n",
       " 1520,\n",
       " 1526,\n",
       " 1528,\n",
       " 1531,\n",
       " 1536,\n",
       " 1537,\n",
       " 1538,\n",
       " 1539,\n",
       " 1540,\n",
       " 1542,\n",
       " 1547,\n",
       " 1549,\n",
       " 1553,\n",
       " 1555,\n",
       " 1556,\n",
       " 1557,\n",
       " 1558,\n",
       " 1559,\n",
       " 1560,\n",
       " 1561,\n",
       " 1569,\n",
       " 1575,\n",
       " 1576,\n",
       " 1577,\n",
       " 1578,\n",
       " 1580,\n",
       " 1581,\n",
       " 1583,\n",
       " 1585,\n",
       " 1586,\n",
       " 1587,\n",
       " 1588,\n",
       " 1589,\n",
       " 1591,\n",
       " 1592,\n",
       " 1594,\n",
       " 1597,\n",
       " 1598,\n",
       " 1600,\n",
       " 1602,\n",
       " 1604,\n",
       " 1605,\n",
       " 1607,\n",
       " 1608,\n",
       " 1609,\n",
       " 1610,\n",
       " 1611,\n",
       " 1612,\n",
       " 1616,\n",
       " 1618,\n",
       " 1621,\n",
       " 1622,\n",
       " 1625,\n",
       " 1628,\n",
       " 1632,\n",
       " 1634,\n",
       " 1636,\n",
       " 1638,\n",
       " 1643,\n",
       " 1650,\n",
       " 1651,\n",
       " 1657,\n",
       " 1661,\n",
       " 1664,\n",
       " 1665,\n",
       " 1672,\n",
       " 1673,\n",
       " 1675,\n",
       " 1678,\n",
       " 1679,\n",
       " 1681,\n",
       " 1683,\n",
       " 1685,\n",
       " 1686,\n",
       " 1691,\n",
       " 1692,\n",
       " 1693,\n",
       " 1694,\n",
       " 1707,\n",
       " 1711,\n",
       " 1714,\n",
       " 1717,\n",
       " 1720,\n",
       " 1725,\n",
       " 1726,\n",
       " 1730,\n",
       " 1731,\n",
       " 1732,\n",
       " 1734,\n",
       " 1735,\n",
       " 1736,\n",
       " 1737,\n",
       " 1739,\n",
       " 1740,\n",
       " 1741,\n",
       " 1743,\n",
       " 1744,\n",
       " 1748,\n",
       " 1749,\n",
       " 1751,\n",
       " 1752,\n",
       " 1753,\n",
       " 1754,\n",
       " 1755,\n",
       " 1757,\n",
       " 1758,\n",
       " 1759,\n",
       " 1762,\n",
       " 1763,\n",
       " 1767,\n",
       " 1775,\n",
       " 1776,\n",
       " 1777,\n",
       " 1780,\n",
       " 1781,\n",
       " 1783,\n",
       " 1784,\n",
       " 1788,\n",
       " 1789,\n",
       " 1792,\n",
       " 1794,\n",
       " 1795,\n",
       " 1798,\n",
       " 1799,\n",
       " 1801,\n",
       " 1802,\n",
       " 1803,\n",
       " 1806,\n",
       " 1809,\n",
       " 1810,\n",
       " 1816,\n",
       " 1817,\n",
       " 1819,\n",
       " 1820,\n",
       " 1821,\n",
       " 1822,\n",
       " 1830,\n",
       " 1831,\n",
       " 1840,\n",
       " 1843,\n",
       " 1844,\n",
       " 1846,\n",
       " 1847,\n",
       " 1849,\n",
       " 1850,\n",
       " 1852,\n",
       " 1858,\n",
       " 1861,\n",
       " 1863,\n",
       " 1865,\n",
       " 1866,\n",
       " 1876,\n",
       " 1877,\n",
       " 1878,\n",
       " 1880,\n",
       " 1883,\n",
       " 1884,\n",
       " 1888,\n",
       " 1889,\n",
       " 1890,\n",
       " 1891,\n",
       " 1893,\n",
       " 1894,\n",
       " 1896,\n",
       " 1897,\n",
       " 1901,\n",
       " 1904,\n",
       " 1905,\n",
       " 1910,\n",
       " 1914,\n",
       " 1917,\n",
       " 1918,\n",
       " 1920,\n",
       " 1922,\n",
       " 1923,\n",
       " 1924,\n",
       " 1927,\n",
       " 1931,\n",
       " 1935,\n",
       " 1936,\n",
       " 1940,\n",
       " 1941,\n",
       " 1942,\n",
       " 1950,\n",
       " 1951,\n",
       " 1952,\n",
       " 1953,\n",
       " 1959,\n",
       " 1960,\n",
       " 1963,\n",
       " 1969,\n",
       " 1972,\n",
       " 1973,\n",
       " 1974,\n",
       " 1978,\n",
       " 1980,\n",
       " 1983,\n",
       " 1986,\n",
       " 1987,\n",
       " 1989,\n",
       " 1992,\n",
       " 1996,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2010,\n",
       " 2011,\n",
       " 2012,\n",
       " 2017,\n",
       " 2027,\n",
       " 2029,\n",
       " 2031,\n",
       " 2035,\n",
       " 2037,\n",
       " 2041,\n",
       " 2043,\n",
       " 2045,\n",
       " 2046,\n",
       " 2047,\n",
       " 2054,\n",
       " 2057,\n",
       " 2059,\n",
       " 2069,\n",
       " 2074,\n",
       " 2075,\n",
       " 2076,\n",
       " 2078,\n",
       " 2080,\n",
       " 2081,\n",
       " 2082,\n",
       " 2083,\n",
       " 2084,\n",
       " 2085,\n",
       " 2086,\n",
       " 2108,\n",
       " 2109,\n",
       " 2114,\n",
       " 2115,\n",
       " 2119,\n",
       " 2120,\n",
       " 2124,\n",
       " 2132,\n",
       " 2133,\n",
       " 2137,\n",
       " 2138,\n",
       " 2143,\n",
       " 2147,\n",
       " 2148,\n",
       " 2151,\n",
       " 2153,\n",
       " 2158,\n",
       " 2164,\n",
       " 2166,\n",
       " 2173,\n",
       " 2174,\n",
       " 2175,\n",
       " 2176,\n",
       " 2178,\n",
       " 2180,\n",
       " 2181,\n",
       " 2182,\n",
       " 2183,\n",
       " 2184,\n",
       " 2190,\n",
       " 2191,\n",
       " 2193,\n",
       " 2194,\n",
       " 2197,\n",
       " 2198,\n",
       " 2200,\n",
       " 2204,\n",
       " 2206,\n",
       " 2208,\n",
       " 2209,\n",
       " 2210,\n",
       " 2211,\n",
       " 2213,\n",
       " 2214,\n",
       " 2215,\n",
       " 2216,\n",
       " 2217,\n",
       " 2218,\n",
       " 2219,\n",
       " 2220,\n",
       " 2221,\n",
       " 2226,\n",
       " 2227,\n",
       " 2237,\n",
       " 2239,\n",
       " 2240,\n",
       " 2243,\n",
       " 2244,\n",
       " 2245,\n",
       " 2246,\n",
       " 2251,\n",
       " 2252,\n",
       " 2263,\n",
       " 2264,\n",
       " 2265,\n",
       " 2266,\n",
       " 2267,\n",
       " 2268,\n",
       " 2275,\n",
       " 2277,\n",
       " 2278,\n",
       " 2279,\n",
       " 2280,\n",
       " 2284,\n",
       " 2285,\n",
       " 2289,\n",
       " 2291,\n",
       " 2294,\n",
       " 2296,\n",
       " 2298,\n",
       " 2299,\n",
       " 2303,\n",
       " 2305,\n",
       " 2306,\n",
       " 2311,\n",
       " 2312,\n",
       " 2313,\n",
       " 2314,\n",
       " 2315,\n",
       " 2316,\n",
       " 2318,\n",
       " 2319,\n",
       " 2320,\n",
       " 2321,\n",
       " 2322,\n",
       " 2325,\n",
       " 2326,\n",
       " 2328,\n",
       " 2329,\n",
       " 2332,\n",
       " 2334,\n",
       " 2335,\n",
       " 2336,\n",
       " 2337,\n",
       " 2340,\n",
       " 2341,\n",
       " 2342,\n",
       " 2343,\n",
       " 2346,\n",
       " 2347,\n",
       " 2348,\n",
       " 2355,\n",
       " 2363,\n",
       " 2369,\n",
       " 2370,\n",
       " 2379,\n",
       " 2380,\n",
       " 2381,\n",
       " 2382,\n",
       " 2390,\n",
       " 2391,\n",
       " 2392,\n",
       " 2394,\n",
       " 2396,\n",
       " 2398,\n",
       " 2399,\n",
       " 2402,\n",
       " 2403,\n",
       " 2404,\n",
       " 2405,\n",
       " 2407,\n",
       " 2409,\n",
       " 2410,\n",
       " 2411,\n",
       " 2412,\n",
       " 2413,\n",
       " 2414,\n",
       " 2415,\n",
       " 2416,\n",
       " 2418,\n",
       " 2419,\n",
       " 2420,\n",
       " 2421,\n",
       " 2422,\n",
       " 2427,\n",
       " 2429,\n",
       " 2430,\n",
       " 2434,\n",
       " 2438,\n",
       " 2449,\n",
       " 2455,\n",
       " 2456,\n",
       " 2459,\n",
       " 2461,\n",
       " 2468,\n",
       " 2471,\n",
       " 2473,\n",
       " 2474,\n",
       " ...]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncols=data[0].shape[1]  #num of columns, i.e. num of words\n",
    "ncols\n",
    "selected_data=data[0][:, range(2)]\n",
    "selected_data.shape\n",
    "len(data[0].getcol(2).nonzero()[0])\n",
    "selected_cols.append(2)\n",
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform sparse matrix of word counts to sparse matrix of tf*idf\n",
    "#norm=I2, use IDF, tf=tf+tf*idf \n",
    "#reference (http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)\n",
    "tfidfTransformer = TfidfTransformer(norm='l1')\n",
    "data_tfidf = tfidfTransformer.fit_transform(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0260323009056\n"
     ]
    }
   ],
   "source": [
    "#using latent semantic analysis; when substract column means from column values, it's the same as PCA. \n",
    "#reference http://scikit-learn.org/stable/modules/decomposition.html\n",
    "#we can't center the data_tfidf here, as it will destroy the sparsity (http://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "svd=TruncatedSVD(n_components=2)\n",
    "x = svd.fit(data_tfidf)\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print explained_variance\n",
    "\n",
    "#made it a function in python/test.py \n",
    "\n",
    "#it turned out using raw count (data) matrix resulted in much higher variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x204562 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 13021 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf.shape\n",
    "data_tfidf.getrow(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run python/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "testmethod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Truncated SVD, something similar to PCA to the doc_word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pcaOnSparseMatrix (n_components, sparseMatrix):\n",
    "    svd=TruncatedSVD(n_components)\n",
    "    X = svd.fit(sparseMatrix)\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    return explained_variance   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71932344647114388"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaOnSparseMatrix (20, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#given a sparse matrix, centralize it by substrcting cell value from its column mean\n",
    "def getCentralMatrix (sparseMatrix):\n",
    "    for i in range(data_tfidf.shape[1]):\n",
    "        col=data_tfidf.getcol(i)\n",
    "        colmean=numpy.mean(col.toarray())\n",
    "        \n",
    "col=data_tfidf.getcol(0)\n",
    "#data_tfidf.mean(data_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrixlib.defmatrix.matrix"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#col-numpy.mean(col.toarray())\n",
    "type(data_tfidf.sum(axis=0))\n",
    "#numpy.mean(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_doc_tdidf = csr_matrix.transpose(data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25119816686793589"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaOnSparseMatrix (20, word_doc_tdidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21976027895420441"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaOnSparseMatrix (20, data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#word_doc = csr_matrix.transpose(data[0])\n",
    "#pcaOnSparseMatrix (20, word_doc)\n",
    "svd=TruncatedSVD(n_components=10)\n",
    "X = svd.fit_transform(data[0])\n",
    "#get mapping from word to PC\n",
    "#pandas.DataFrame(svd.components_, index=[\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\",\"PC9\",\"PC10\",\"PC11\",\"PC12\",\"PC13\",\"PC14\",\"PC15\",\"PC16\",\"PC17\",\"PC18\",\"PC19\",\"PC20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719325237635\n"
     ]
    }
   ],
   "source": [
    "#get explained_variance for SVD\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333150098171\n",
      "0.81563366975\n",
      "0.865783999522\n",
      "0.896571856106\n"
     ]
    }
   ],
   "source": [
    "print pcaOnSparseMatrix (2, data[0])\n",
    "print pcaOnSparseMatrix (40, data[0])\n",
    "print pcaOnSparseMatrix (60, data[0])\n",
    "print pcaOnSparseMatrix (80, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614157229237\n",
      "0.775936808712\n",
      "0.843744565519\n",
      "0.882888210901\n",
      "0.908383121804\n",
      "0.918405932645\n"
     ]
    }
   ],
   "source": [
    "print pcaOnSparseMatrix (10, data[0])\n",
    "print pcaOnSparseMatrix (30, data[0])\n",
    "print pcaOnSparseMatrix (50, data[0])\n",
    "print pcaOnSparseMatrix (70, data[0])\n",
    "print pcaOnSparseMatrix (90, data[0])\n",
    "print pcaOnSparseMatrix (100, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204562L, 10L)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_doc = csr_matrix.transpose(data[0])\n",
    "svd=TruncatedSVD(n_components=10)\n",
    "X = svd.fit_transform(word_doc)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate word similarity, with word represented by PCs\n",
    "and then we compare it with words represented by its co-occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_word_matrix=pandas.DataFrame(svd.components_, index=[\"PC1\",\"PC2\"])\n",
    "type(pc_word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w0_inPcs=[w[0] for w in svd.components_]\n",
    "w1_inPcs=[w[1] for w in svd.components_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99353392267172802"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute cosine similairty between 2 words (represented in PCs)\n",
    "#we have it substracted by 1 because cosine() computes cosine distance, it actually returns 1-cossim()\n",
    "#http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n",
    "1-cosine(w0_inPcs, w1_inPcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now deal with reading into the dictionary\n",
    "\n",
    "read it into a list\n",
    "also build a hash (dictionary), so that given a word, such as 'history' or 'hlstory' we can find its index in the array through searching in the hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlist=[]\n",
    "f=open(\"C:\\\\Users\\\\Miao\\\\Desktop\\\\Courses\\\\S675 Statistical Learning\\\\final\\\\vocab.txt\", 'r')\n",
    "for line in f:\n",
    "    wordlist.append(line.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a_nd',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aac',\n",
       " 'aachen',\n",
       " 'aad',\n",
       " 'aadth',\n",
       " 'aae',\n",
       " 'aaer',\n",
       " 'aaf',\n",
       " 'aah',\n",
       " 'aahmes',\n",
       " 'aai',\n",
       " 'aaid',\n",
       " 'aaion',\n",
       " 'aaions',\n",
       " 'aaith',\n",
       " 'aaj',\n",
       " 'aak',\n",
       " 'aal',\n",
       " 'aalensis',\n",
       " 'aam',\n",
       " 'aan',\n",
       " 'aana',\n",
       " 'aand',\n",
       " 'aans',\n",
       " 'aao',\n",
       " 'aap',\n",
       " 'aar',\n",
       " 'aarau',\n",
       " 'aard',\n",
       " 'aare',\n",
       " 'aargau',\n",
       " 'aaron',\n",
       " 'aaronite',\n",
       " 'aas',\n",
       " 'aat',\n",
       " 'aatat',\n",
       " 'aatr',\n",
       " 'aav',\n",
       " 'aavaan',\n",
       " 'aavay',\n",
       " 'aax',\n",
       " 'aay',\n",
       " 'aaya',\n",
       " 'aays',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'ababde',\n",
       " 'ababdeh',\n",
       " 'ababil',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abad',\n",
       " 'abada',\n",
       " 'abade',\n",
       " 'abades',\n",
       " 'abadia',\n",
       " 'abaft',\n",
       " 'abagi',\n",
       " 'abai',\n",
       " 'abaixo',\n",
       " 'abaj',\n",
       " 'abajo',\n",
       " 'abal',\n",
       " 'abalorios',\n",
       " 'aban',\n",
       " 'abancay',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandonna',\n",
       " 'abandonnant',\n",
       " 'abandonne',\n",
       " 'abandonnee',\n",
       " 'abandonner',\n",
       " 'abandonnes',\n",
       " 'abandono',\n",
       " 'abandons',\n",
       " 'abang',\n",
       " 'abarbenel',\n",
       " 'abaris',\n",
       " 'abas',\n",
       " 'abase',\n",
       " 'abased',\n",
       " 'abasement',\n",
       " 'abases',\n",
       " 'abash',\n",
       " 'abashed',\n",
       " 'abasing',\n",
       " 'abasis',\n",
       " 'abassines',\n",
       " 'abat',\n",
       " 'abate',\n",
       " 'abated',\n",
       " 'abatement',\n",
       " 'abatements',\n",
       " 'abates',\n",
       " 'abateth',\n",
       " 'abati',\n",
       " 'abating',\n",
       " 'abatis',\n",
       " 'abattis',\n",
       " 'abattoir',\n",
       " 'abattoirs',\n",
       " 'abattre',\n",
       " 'abattu',\n",
       " 'abawi',\n",
       " 'abax',\n",
       " 'abaxo',\n",
       " 'abay',\n",
       " 'abb',\n",
       " 'abba',\n",
       " 'abbadie',\n",
       " 'abbai',\n",
       " 'abbas',\n",
       " 'abbate',\n",
       " 'abbati',\n",
       " 'abbatis',\n",
       " 'abbaye',\n",
       " 'abbc',\n",
       " 'abbd',\n",
       " 'abbe',\n",
       " 'abbefs',\n",
       " 'abbes',\n",
       " 'abbess',\n",
       " 'abbesse',\n",
       " 'abbesses',\n",
       " 'abbeville',\n",
       " 'abbey',\n",
       " 'abbeys',\n",
       " 'abbi',\n",
       " 'abbia',\n",
       " 'abbiamo',\n",
       " 'abbies',\n",
       " 'abbild',\n",
       " 'abbildung',\n",
       " 'abbildungen',\n",
       " 'abbo',\n",
       " 'abbot',\n",
       " 'abbotrule',\n",
       " 'abbots',\n",
       " 'abbotsbury',\n",
       " 'abbotsford',\n",
       " 'abbott',\n",
       " 'abbps',\n",
       " 'abbre',\n",
       " 'abbrev',\n",
       " 'abbreviata',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abbreviates',\n",
       " 'abbreviati',\n",
       " 'abbreviating',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbreviatis',\n",
       " 'abbreviato',\n",
       " 'abbreviatum',\n",
       " 'abbreviatus',\n",
       " 'abbs',\n",
       " 'abbt',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abcd',\n",
       " 'abd',\n",
       " 'abdael',\n",
       " 'abdal',\n",
       " 'abdali',\n",
       " 'abdalis',\n",
       " 'abdalla',\n",
       " 'abdallah',\n",
       " 'abdallatif',\n",
       " 'abddm',\n",
       " 'abdel',\n",
       " 'abdelcader',\n",
       " 'abdelm',\n",
       " 'abdelmelech',\n",
       " 'abdera',\n",
       " 'abderites',\n",
       " 'abdicate',\n",
       " 'abdicated',\n",
       " 'abdicates',\n",
       " 'abdicating',\n",
       " 'abdication',\n",
       " 'abdiel',\n",
       " 'abdita',\n",
       " 'abdo',\n",
       " 'abdom',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdomi',\n",
       " 'abdomina',\n",
       " 'abdominal',\n",
       " 'abdominale',\n",
       " 'abdominales',\n",
       " 'abdominalis',\n",
       " 'abdominc',\n",
       " 'abdomine',\n",
       " 'abdomineque',\n",
       " 'abdominis',\n",
       " 'abdominisque',\n",
       " 'abdomino',\n",
       " 'abdool',\n",
       " 'abdoolah',\n",
       " 'abdoolla',\n",
       " 'abdoollah',\n",
       " 'abdoulrahman',\n",
       " 'abdu',\n",
       " 'abducens',\n",
       " 'abducere',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductor',\n",
       " 'abductors',\n",
       " 'abdul',\n",
       " 'abdulkader',\n",
       " 'abdulla',\n",
       " 'abdullah',\n",
       " 'abdulraman',\n",
       " 'abdurrahman',\n",
       " 'abdut',\n",
       " 'abdy',\n",
       " 'abe',\n",
       " 'abea',\n",
       " 'abeady',\n",
       " 'abeam',\n",
       " 'abecedarium',\n",
       " 'abechuco',\n",
       " 'abed',\n",
       " 'abeghan',\n",
       " 'abeille',\n",
       " 'abeilles',\n",
       " 'abeken',\n",
       " 'abel',\n",
       " 'abelard',\n",
       " 'abele',\n",
       " 'abeles',\n",
       " 'abelia',\n",
       " 'abell',\n",
       " 'abella',\n",
       " 'abelmoschus',\n",
       " 'aben',\n",
       " 'abenamar',\n",
       " 'abencerrages',\n",
       " 'abencerrago',\n",
       " 'aber',\n",
       " 'aberarder',\n",
       " 'aberbrothock',\n",
       " 'abercorn',\n",
       " 'abercrombie',\n",
       " 'abercromby',\n",
       " 'aberd',\n",
       " 'aberdeen',\n",
       " 'aberdeens',\n",
       " 'aberdeenshire',\n",
       " 'aberdour',\n",
       " 'aberfeldie',\n",
       " 'aberfoyle',\n",
       " 'abergavenny',\n",
       " 'aberlady',\n",
       " 'abernethy',\n",
       " 'aberrans',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrations',\n",
       " 'aberrationum',\n",
       " 'abert',\n",
       " 'aberti',\n",
       " 'aberystwith',\n",
       " 'abesse',\n",
       " 'abesset',\n",
       " 'abest',\n",
       " 'abet',\n",
       " 'abete',\n",
       " 'abethdin',\n",
       " 'abetone',\n",
       " 'abetted',\n",
       " 'abetter',\n",
       " 'abetting',\n",
       " 'abettor',\n",
       " 'abettors',\n",
       " 'abeunt',\n",
       " 'abeuntibus',\n",
       " 'abeyance',\n",
       " 'abfalom',\n",
       " 'abfblutely',\n",
       " 'abfence',\n",
       " 'abfent',\n",
       " 'abfented',\n",
       " 'abfo',\n",
       " 'abfolutcly',\n",
       " 'abfolute',\n",
       " 'abfolutely',\n",
       " 'abfolution',\n",
       " 'abfolved',\n",
       " 'abfor',\n",
       " 'abforb',\n",
       " 'abforbed',\n",
       " 'abforbent',\n",
       " 'abforbents',\n",
       " 'abforbing',\n",
       " 'abforbs',\n",
       " 'abforp',\n",
       " 'abforption',\n",
       " 'abforptions',\n",
       " 'abfque',\n",
       " 'abftain',\n",
       " 'abftinence',\n",
       " 'abftract',\n",
       " 'abftracted',\n",
       " 'abftrad',\n",
       " 'abftradl',\n",
       " 'abftrufe',\n",
       " 'abfurd',\n",
       " 'abfurdities',\n",
       " 'abfurdity',\n",
       " 'abfynthium',\n",
       " 'abh',\n",
       " 'abha',\n",
       " 'abhand',\n",
       " 'abhandl',\n",
       " 'abhandlung',\n",
       " 'abhandlungen',\n",
       " 'abhi',\n",
       " 'abhinc',\n",
       " 'abhor',\n",
       " 'abhorr',\n",
       " 'abhorre',\n",
       " 'abhorred',\n",
       " 'abhorrence',\n",
       " 'abhorrent',\n",
       " 'abhorrer',\n",
       " 'abhorrers',\n",
       " 'abhorreth',\n",
       " 'abhorring',\n",
       " 'abhors',\n",
       " 'abi',\n",
       " 'abia',\n",
       " 'abiad',\n",
       " 'abiathar',\n",
       " 'abich',\n",
       " 'abid',\n",
       " 'abide',\n",
       " 'abided',\n",
       " 'abides',\n",
       " 'abideth',\n",
       " 'abiding',\n",
       " 'abie',\n",
       " 'abies',\n",
       " 'abiete',\n",
       " 'abietina',\n",
       " 'abietinum',\n",
       " 'abietis',\n",
       " 'abigail',\n",
       " 'abigoom',\n",
       " 'abihty',\n",
       " 'abiit',\n",
       " 'abijam',\n",
       " 'abil',\n",
       " 'abildgaard',\n",
       " 'abilitie',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abimdance',\n",
       " 'abime',\n",
       " 'abimelech',\n",
       " 'abing',\n",
       " 'abingdon',\n",
       " 'abinger',\n",
       " 'abington',\n",
       " 'abions',\n",
       " 'abipon',\n",
       " 'abiponer',\n",
       " 'abipones',\n",
       " 'abiponian',\n",
       " 'abiram',\n",
       " 'abire',\n",
       " 'abishag',\n",
       " 'abishai',\n",
       " 'abispal',\n",
       " 'abit',\n",
       " 'abito',\n",
       " 'abiuty',\n",
       " 'abje',\n",
       " 'abject',\n",
       " 'abjection',\n",
       " 'abjectly',\n",
       " 'abjectness',\n",
       " 'abjed',\n",
       " 'abjuration',\n",
       " 'abjure',\n",
       " 'abjured',\n",
       " 'abjures',\n",
       " 'abjuring',\n",
       " 'abl',\n",
       " 'ablack',\n",
       " 'ablancourt',\n",
       " 'ablaqueation',\n",
       " 'ablata',\n",
       " 'ablation',\n",
       " 'ablative',\n",
       " 'ablaze',\n",
       " 'ablc',\n",
       " 'abled',\n",
       " 'ableft',\n",
       " 'ableness',\n",
       " 'abler',\n",
       " 'ables',\n",
       " 'ablest',\n",
       " 'abli',\n",
       " 'ablo',\n",
       " 'ablution',\n",
       " 'ablutions',\n",
       " 'ably',\n",
       " 'abm',\n",
       " 'abnegation',\n",
       " 'abner',\n",
       " 'abnormal',\n",
       " 'abnormally',\n",
       " 'abnormis',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'aboat',\n",
       " 'abode',\n",
       " 'abodes',\n",
       " 'aboh',\n",
       " 'aboi',\n",
       " 'aboiit',\n",
       " 'abol',\n",
       " 'abola',\n",
       " 'aboli',\n",
       " 'abolifhed',\n",
       " 'aboliihed',\n",
       " 'abolir',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolishes',\n",
       " 'abolishing',\n",
       " 'abolishment',\n",
       " 'abolisht',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abom',\n",
       " 'aboma',\n",
       " 'abomasum',\n",
       " 'abomi',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abominated',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'abondamment',\n",
       " 'abondance',\n",
       " 'abondant',\n",
       " 'abondante',\n",
       " 'abondantes',\n",
       " 'abondants',\n",
       " 'abonde',\n",
       " 'abondent',\n",
       " 'abong',\n",
       " 'abont',\n",
       " 'aboo',\n",
       " 'aboon',\n",
       " 'aboosimbel',\n",
       " 'aboot',\n",
       " 'abor',\n",
       " 'abord',\n",
       " 'aborde',\n",
       " 'abore',\n",
       " 'abori',\n",
       " 'aboriginal',\n",
       " 'aboriginally',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abortiv',\n",
       " 'abortiva',\n",
       " 'abortive',\n",
       " 'abortively',\n",
       " 'abortivis',\n",
       " 'abortivo',\n",
       " 'abortu',\n",
       " 'abos',\n",
       " 'abote',\n",
       " 'abotit',\n",
       " 'abou',\n",
       " 'abouabdoulah',\n",
       " 'abouc',\n",
       " 'aboue',\n",
       " 'abouf',\n",
       " 'aboukir',\n",
       " 'aboul',\n",
       " 'aboun',\n",
       " 'abouna',\n",
       " 'abound',\n",
       " 'aboundance',\n",
       " 'aboundantly',\n",
       " 'abounded',\n",
       " 'aboundeth',\n",
       " 'abounding',\n",
       " 'abounds',\n",
       " 'abour',\n",
       " 'aboute',\n",
       " 'aboutir',\n",
       " 'aboutissent',\n",
       " 'aboutit',\n",
       " 'abouts',\n",
       " 'aboutthe',\n",
       " 'abov',\n",
       " 'aboveground',\n",
       " 'abovemen',\n",
       " 'abovemention',\n",
       " 'abovementioned',\n",
       " 'abovenamed',\n",
       " 'abovesaid',\n",
       " 'abovit',\n",
       " 'abovo',\n",
       " 'abowt',\n",
       " 'aboye',\n",
       " 'abp',\n",
       " 'abput',\n",
       " 'abpve',\n",
       " 'abr',\n",
       " 'abra',\n",
       " 'abrade',\n",
       " 'abraded',\n",
       " 'abrading',\n",
       " 'abraham',\n",
       " 'abrahamic',\n",
       " 'abrahamidce',\n",
       " 'abram',\n",
       " 'abramis',\n",
       " 'abran',\n",
       " 'abrantcs',\n",
       " 'abrantea',\n",
       " 'abrantes',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abrautes',\n",
       " 'abraxas',\n",
       " 'abre',\n",
       " 'abreaft',\n",
       " 'abreast',\n",
       " 'abredonensis',\n",
       " 'abreft',\n",
       " 'abreg',\n",
       " 'abrege',\n",
       " 'abregee',\n",
       " 'abreha',\n",
       " 'abreu',\n",
       " 'abri',\n",
       " 'abricius',\n",
       " 'abricolla',\n",
       " 'abricot',\n",
       " 'abricotee',\n",
       " 'abricotier',\n",
       " 'abricots',\n",
       " 'abridg',\n",
       " 'abridge',\n",
       " 'abridged',\n",
       " 'abridgement',\n",
       " 'abridgements',\n",
       " 'abridger',\n",
       " 'abridges',\n",
       " 'abridging',\n",
       " 'abridgment',\n",
       " 'abridgments',\n",
       " 'abril',\n",
       " 'abro',\n",
       " 'abroach',\n",
       " 'abroad',\n",
       " 'abroade',\n",
       " 'abrode',\n",
       " 'abrogate',\n",
       " 'abrogated',\n",
       " 'abrogates',\n",
       " 'abrogating',\n",
       " 'abrogation',\n",
       " 'abrolhos',\n",
       " 'abroma',\n",
       " 'abrostomus',\n",
       " 'abrotanella',\n",
       " 'abrotanum',\n",
       " 'abrud',\n",
       " 'abrupt',\n",
       " 'abrupta',\n",
       " 'abrupte',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abruptum',\n",
       " 'abrus',\n",
       " 'abruzzi',\n",
       " 'abruzzo',\n",
       " 'abs',\n",
       " 'absalom',\n",
       " 'absalon',\n",
       " 'abscess',\n",
       " 'abscesses',\n",
       " 'abscinditur',\n",
       " 'abscissa',\n",
       " 'abscissae',\n",
       " 'abscond',\n",
       " 'absconded',\n",
       " 'absconding',\n",
       " 'absconditum',\n",
       " 'absconds',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absenee',\n",
       " 'absens',\n",
       " 'absent',\n",
       " 'absente',\n",
       " 'absented',\n",
       " 'absentee',\n",
       " 'absenteeism',\n",
       " 'absentees',\n",
       " 'absentes',\n",
       " 'absentia',\n",
       " 'absenting',\n",
       " 'absentis',\n",
       " 'absents',\n",
       " 'absimilis',\n",
       " 'absint',\n",
       " 'absinthe',\n",
       " 'absinthium',\n",
       " 'absit',\n",
       " 'abso',\n",
       " 'absol',\n",
       " 'absolon',\n",
       " 'absolu',\n",
       " 'absolue',\n",
       " 'absolument',\n",
       " 'absolut',\n",
       " 'absoluta',\n",
       " 'absolutam',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoluteness',\n",
       " 'absolution',\n",
       " 'absolutions',\n",
       " 'absolutis',\n",
       " 'absolutism',\n",
       " 'absolutists',\n",
       " 'absolutum',\n",
       " 'absolutus',\n",
       " 'absolv',\n",
       " 'absolve',\n",
       " 'absolved',\n",
       " 'absolves',\n",
       " 'absolvi',\n",
       " 'absolving',\n",
       " 'absolvit',\n",
       " 'absolvitur',\n",
       " 'absor',\n",
       " 'absorb',\n",
       " 'absorbe',\n",
       " 'absorbed',\n",
       " 'absorbent',\n",
       " 'absorbents',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorp',\n",
       " 'absorption',\n",
       " 'absorptione',\n",
       " 'absorptions',\n",
       " 'absorptive',\n",
       " 'absque',\n",
       " 'abst',\n",
       " 'abstain',\n",
       " 'abstained',\n",
       " 'abstaining',\n",
       " 'abstains',\n",
       " 'abstemious',\n",
       " 'abstemiously',\n",
       " 'abstemiousness',\n",
       " 'abstenir',\n",
       " 'abstersive',\n",
       " 'absti',\n",
       " 'abstin',\n",
       " 'abstine',\n",
       " 'abstinence',\n",
       " 'abstinences',\n",
       " 'abstinent',\n",
       " 'abstinentia',\n",
       " 'abstinere',\n",
       " 'abstract',\n",
       " 'abstracta',\n",
       " 'abstractae',\n",
       " 'abstractam',\n",
       " 'abstracted',\n",
       " 'abstractedly',\n",
       " 'abstractedness',\n",
       " 'abstracti',\n",
       " 'abstracting',\n",
       " 'abstraction',\n",
       " 'abstractions',\n",
       " 'abstractis',\n",
       " 'abstractly',\n",
       " 'abstracts',\n",
       " 'abstractum',\n",
       " 'abstraet',\n",
       " 'abstruse',\n",
       " 'abstruseness',\n",
       " 'abstrusest',\n",
       " 'abstulit',\n",
       " 'absunt',\n",
       " 'absur',\n",
       " 'absurd',\n",
       " 'absurda',\n",
       " 'absurde',\n",
       " 'absurdest',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'absurdo',\n",
       " 'absurdum',\n",
       " 'absynthium',\n",
       " 'abt',\n",
       " 'abth',\n",
       " 'abtheil',\n",
       " 'abtheilung',\n",
       " 'abu',\n",
       " 'abubekr',\n",
       " 'abud',\n",
       " 'abufe',\n",
       " 'abufed',\n",
       " 'abufes',\n",
       " 'abufing',\n",
       " 'abufive',\n",
       " 'abul',\n",
       " 'abulfeda',\n",
       " 'abun',\n",
       " 'abuna',\n",
       " 'abund',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantia',\n",
       " 'abundantly',\n",
       " 'abundat',\n",
       " 'abunde',\n",
       " 'abune',\n",
       " 'abury',\n",
       " 'abus',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusheher',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abusu',\n",
       " 'abut',\n",
       " 'abuti',\n",
       " 'abutilon',\n",
       " 'abutment',\n",
       " 'abutments',\n",
       " 'abuts',\n",
       " 'abutted',\n",
       " 'abutting',\n",
       " 'abutua',\n",
       " 'abw',\n",
       " 'aby',\n",
       " 'abyde',\n",
       " 'abydenus',\n",
       " 'abydos',\n",
       " 'abydus',\n",
       " 'abyffinia',\n",
       " 'abyfs',\n",
       " 'abys',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'abysses',\n",
       " 'abyssi',\n",
       " 'abyssicola',\n",
       " 'abyssinia',\n",
       " 'abyssinian',\n",
       " 'abyssinians',\n",
       " 'abyssinica',\n",
       " 'abyssinicum',\n",
       " 'abyssinicus',\n",
       " 'abyssinie',\n",
       " 'abyssins',\n",
       " 'abyssus',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'acab',\n",
       " 'acaba',\n",
       " 'acabado',\n",
       " 'acabar',\n",
       " 'acabo',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'acacis',\n",
       " 'acacius',\n",
       " 'acad',\n",
       " 'acadcmie',\n",
       " 'acade',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'academia',\n",
       " 'academiae',\n",
       " 'academiam',\n",
       " 'academiarum',\n",
       " 'academias',\n",
       " 'academic',\n",
       " 'academica',\n",
       " 'academicae',\n",
       " 'academical',\n",
       " 'academicce',\n",
       " 'academici',\n",
       " 'academician',\n",
       " 'academicians',\n",
       " 'academicis',\n",
       " 'academico',\n",
       " 'academicorum',\n",
       " 'academicos',\n",
       " 'academics',\n",
       " 'academicum',\n",
       " 'academicus',\n",
       " 'academie',\n",
       " 'academiens',\n",
       " 'academies',\n",
       " 'academists',\n",
       " 'academy',\n",
       " 'acadia',\n",
       " 'acadian',\n",
       " 'acadians',\n",
       " 'acadica',\n",
       " 'acadie',\n",
       " 'acajou',\n",
       " 'acajutla',\n",
       " 'acaleph',\n",
       " 'acalepha',\n",
       " 'acalephae',\n",
       " 'acalephan',\n",
       " 'acalephce',\n",
       " 'acalephe',\n",
       " 'acalephes',\n",
       " 'acalephs',\n",
       " 'acalephse',\n",
       " 'acalephx',\n",
       " 'acalissus',\n",
       " 'acalles',\n",
       " 'acalypha',\n",
       " 'acamarchis',\n",
       " 'acan',\n",
       " 'acana',\n",
       " 'acanth',\n",
       " 'acanthacea',\n",
       " 'acanthaceae',\n",
       " 'acanthacece',\n",
       " 'acanthia',\n",
       " 'acanthians',\n",
       " 'acanthias',\n",
       " 'acanthium',\n",
       " 'acanthiza',\n",
       " 'acantho',\n",
       " 'acanthocephala',\n",
       " 'acanthocerus',\n",
       " 'acanthocinus',\n",
       " 'acanthodes',\n",
       " 'acanthogenys',\n",
       " 'acanthoides',\n",
       " 'acantholabrus',\n",
       " 'acanthonotus',\n",
       " 'acanthonyx',\n",
       " 'acanthophis',\n",
       " 'acanthopterygian',\n",
       " 'acanthopterygians',\n",
       " 'acanthopterygii',\n",
       " 'acanthopterygu',\n",
       " 'acanthopus',\n",
       " 'acanthorhynchus',\n",
       " 'acanthosoma',\n",
       " 'acanthoteuthis',\n",
       " 'acanths',\n",
       " 'acanthurus',\n",
       " 'acanthus',\n",
       " 'acanthylis',\n",
       " 'acapulco',\n",
       " 'acar',\n",
       " 'acaray',\n",
       " 'acari',\n",
       " 'acarnania',\n",
       " 'acarnanian',\n",
       " 'acarnanians',\n",
       " 'acarus',\n",
       " 'acaso',\n",
       " 'acasta',\n",
       " 'acaste',\n",
       " 'acatalepsiam',\n",
       " 'acaule',\n",
       " 'acaulis',\n",
       " 'acbar',\n",
       " 'acc',\n",
       " 'acca',\n",
       " 'accable',\n",
       " 'accad',\n",
       " 'accademia',\n",
       " 'accan',\n",
       " 'acccording',\n",
       " 'acce',\n",
       " 'accedant',\n",
       " 'accedat',\n",
       " 'accede',\n",
       " 'acceded',\n",
       " 'accedens',\n",
       " 'accedente',\n",
       " 'accedere',\n",
       " 'accederet',\n",
       " 'accedes',\n",
       " 'acceding',\n",
       " 'accedit',\n",
       " 'accedunt',\n",
       " 'acceffion',\n",
       " 'accefiion',\n",
       " 'acceflible',\n",
       " 'acceflion',\n",
       " 'accefs',\n",
       " 'acceifion',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'acceleratores',\n",
       " 'accelerer',\n",
       " 'accen',\n",
       " 'accendere',\n",
       " 'accendit',\n",
       " 'accensa',\n",
       " 'accensi',\n",
       " 'accensis',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accenting',\n",
       " 'accentor',\n",
       " 'accents',\n",
       " 'accentual',\n",
       " 'accentuated',\n",
       " 'accentuation',\n",
       " 'accentus',\n",
       " 'acceperit',\n",
       " 'acceperunt',\n",
       " 'accepi',\n",
       " 'accepimus',\n",
       " 'accepisse',\n",
       " 'accepit',\n",
       " 'accept',\n",
       " 'accepta',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptacion',\n",
       " 'acceptam',\n",
       " 'acceptance',\n",
       " 'acceptances',\n",
       " 'acceptation',\n",
       " 'acceptations',\n",
       " 'accepte',\n",
       " 'accepted',\n",
       " 'accepter',\n",
       " 'accepteth',\n",
       " 'accepting',\n",
       " 'acceptis',\n",
       " 'accepto',\n",
       " 'acceptor',\n",
       " 'accepts',\n",
       " 'acceptum',\n",
       " 'acces',\n",
       " 'acceso',\n",
       " 'access',\n",
       " 'accessaries',\n",
       " 'accessary',\n",
       " 'accesse',\n",
       " 'accessed',\n",
       " 'accessere',\n",
       " 'accesserit',\n",
       " 'accesserunt',\n",
       " 'accesses',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessio',\n",
       " 'accession',\n",
       " 'accessione',\n",
       " 'accessiones',\n",
       " ...]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86261\n",
      "85722\n"
     ]
    }
   ],
   "source": [
    "word_index_hash=dict(zip(wordlist, range(len(wordlist))))\n",
    "print word_index_hash['hlstory']\n",
    "print word_index_hash['himself']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function here: calculating cosine similarity between two words represented by PCs\n",
    "def word_similarity_basedOnPCs(w1, w2):\n",
    "    idx1=word_index_hash[w1]\n",
    "    idx2=word_index_hash[w2]\n",
    "    \n",
    "    w1_inPCs=[w[idx1] for w in svd.components_]\n",
    "    w2_inPCs=[w[idx2] for w in svd.components_]\n",
    "    \n",
    "    return 1-cosine(w1_inPCs, w2_inPCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3346477965155471"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity_basedOnPCs('hlstory', 'historv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868327693758\n",
      "0.607230627983\n",
      "0.521518637142\n",
      "-0.647791492866\n"
     ]
    }
   ],
   "source": [
    "#this is for 10 PCs\n",
    "print word_similarity_basedOnPCs('hlstory', 'historv')\n",
    "print word_similarity_basedOnPCs('himselt', 'himself')\n",
    "print word_similarity_basedOnPCs('historv', 'riage')\n",
    "print word_similarity_basedOnPCs('himselt', 'riage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.334647796516\n",
      "-0.113503735498\n",
      "-0.202564632201\n",
      "-0.0425061429269\n"
     ]
    }
   ],
   "source": [
    "#this is for 20 PCS\n",
    "print word_similarity_basedOnPCs('hlstory', 'historv')\n",
    "print word_similarity_basedOnPCs('himselt', 'himself')\n",
    "print word_similarity_basedOnPCs('historv', 'riage')\n",
    "print word_similarity_basedOnPCs('himselt', 'riage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.279018795692\n",
      "0.0551483751981\n",
      "-0.314858738887\n",
      "-0.0636578833615\n"
     ]
    }
   ],
   "source": [
    "#this is for 60 PCs\n",
    "print word_similarity_basedOnPCs('hlstory', 'historv')\n",
    "print word_similarity_basedOnPCs('himselt', 'himself')\n",
    "print word_similarity_basedOnPCs('historv', 'riage')\n",
    "print word_similarity_basedOnPCs('himselt', 'riage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00015217275155651251,\n",
       " 0.00013434925512479854,\n",
       " -0.00018419881671763959,\n",
       " -6.9062195680203144e-05,\n",
       " -0.00037400490179892231,\n",
       " -0.00025386447564968042,\n",
       " -0.00015974273709882874,\n",
       " 0.00057556578242177157,\n",
       " 0.00015906150819033595,\n",
       " -0.00019404735766652696,\n",
       " -0.00011119511109342336,\n",
       " -4.3633642549517927e-05,\n",
       " 0.00014540994302358345,\n",
       " -0.00024142896878784145,\n",
       " -3.6505998134993491e-05,\n",
       " -0.0002686467136335702,\n",
       " -0.00019919261089652965,\n",
       " 0.0004944824663092838,\n",
       " -2.933356770681123e-05,\n",
       " 0.00010887418285739097]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get vector of PCS given a word\n",
    "idx=word_index_hash['historv']\n",
    "w_inPCs=[w[idx] for w in svd.components_]\n",
    "w_inPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  4.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  5.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  9.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [ 12.],\n",
       "       [  0.],\n",
       "       [  4.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  4.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  5.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  3.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  6.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  2.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  1.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.],\n",
       "       [  0.]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get vector of documents for a word\n",
    "idx=word_index_hash['historv']\n",
    "data[0].getcol(idx).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we calculate word co-occurrence matrix from doc-word sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 9 0]\n",
      " [0 7 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 5]]\n",
      "[[4 0]\n",
      " [0 7]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "row  = numpy.array([0, 3, 1, 0])\n",
    "col  = numpy.array([0, 3, 1, 2])\n",
    "datatest = numpy.array([4, 5, 7, 9])\n",
    "toy=coo_matrix((datatest, (row, col)), shape=(4, 4)).toarray()\n",
    "print toy\n",
    "print toy[:, range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 3], dtype=int64), array([0, 2, 1, 3], dtype=int64))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testcoo=coo_matrix(data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   3,   4,   5,   9,  13,  15,  16,  22,  33,  34,  39,  41,\n",
       "         67,  68,  71,  72,  75,  80,  81,  89,  95,  97, 109, 112, 115,\n",
       "        122, 128, 135, 136, 151, 155, 162, 168, 177, 186, 187, 188, 191,\n",
       "        202, 206, 207, 209, 210, 211, 214, 216, 239, 260, 284, 322, 323,\n",
       "        341, 361, 375, 380, 382, 388, 395, 399, 403, 412, 425, 431, 449,\n",
       "        459, 464, 472, 490, 500, 515, 532, 553, 558, 566, 589, 590, 592]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcoo.getcol(0).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcoo.getcol(0).nonzero()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   3,   4,   5,   9,  13,  15,  16,  22,  33,  34,  39,  41,\n",
       "         67,  68,  71,  72,  75,  80,  81,  89,  95,  97, 109, 112, 115,\n",
       "        122, 128, 135, 136, 151, 155, 162, 168, 177, 186, 187, 188, 191,\n",
       "        202, 206, 207, 209, 210, 211, 214, 216, 239, 260, 284, 322, 323,\n",
       "        341, 361, 375, 380, 382, 388, 395, 399, 403, 412, 425, 431, 449,\n",
       "        459, 464, 472, 490, 500, 515, 532, 553, 558, 566, 589, 590, 592]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col0=data_tfidf.getcol(0).nonzero()\n",
    "col0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([177, 188, 202, 216, 491]), array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1=data_tfidf.getcol(1).nonzero()\n",
    "col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 204562)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_tfidf.getcol(1).nonzero()[0])\n",
    "data_tfidf.shape[1]\n",
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177, 188, 202, 216])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap=numpy.intersect1d(col0[0], col1[0])\n",
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.771199723e-05\n",
      "4.2805352146e-06\n",
      "[  5.77119972e-05   4.28053521e-06]\n",
      "min: 4.2805352146e-06\n",
      "<type 'numpy.float64'>\n",
      "0.000417483571079\n",
      "6.19300392742e-05\n",
      "[  4.17483571e-04   6.19300393e-05]\n",
      "min: 6.19300392742e-05\n",
      "<type 'numpy.float64'>\n",
      "1.27087418086e-05\n",
      "1.17826923898e-05\n",
      "[  1.27087418e-05   1.17826924e-05]\n",
      "min: 1.17826923898e-05\n",
      "<type 'numpy.float64'>\n",
      "6.44963213906e-05\n",
      "2.9898330089e-05\n",
      "[  6.44963214e-05   2.98983301e-05]\n",
      "min: 2.9898330089e-05\n",
      "<type 'numpy.float64'>\n",
      "0.000107891596968\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "\n",
    "for k in overlap:\n",
    "    elem1=data_tfidf.getcol(0)[k].toarray()[0][0]\n",
    "    print elem1\n",
    "    \n",
    "    elem2=data_tfidf.getcol(1)[k].toarray()[0][0]\n",
    "    print elem2\n",
    "    \n",
    "    elems=numpy.array([elem1, elem2])\n",
    "    print elems\n",
    "    print \"min: \"+str(numpy.amin(elems))\n",
    "    print type(numpy.amin(elems))\n",
    "    \n",
    "    sum+=numpy.amin(elems)\n",
    "    #print \"min: \"+str(min(elem1,elem2))\n",
    "    \n",
    "print sum\n",
    "print type(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.77119972e-05]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf.getcol(0)[177].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then make a SparseMatrix according to http://www.foldl.me/2014/glove-python/\n",
    "#based on the above scripts, build up the co-occurrence matrix form data matrix\n",
    "#input a word_doc matrix, output the cocurrence matrix\n",
    "#if in a doc, word1 occurs 4 times, word2 occurs 6 times, then I count their co-occurrence as min(4,6)=4\n",
    "def build_cooccur_matrix (word_doc_matrix):\n",
    "    \n",
    "    n_words=word_doc_matrix.shape[1] #number of words\n",
    "    cooccurrence_matrix=lil_matrix((n_words, n_words), dtype=numpy.float64)\n",
    "    \n",
    "    #get column pairs from the matrix, we do it by column because SparseMatrix uses Column storage\n",
    "    for c1 in range(n_words): #column2\n",
    "        for c2 in range(n_words):  #for column2\n",
    "            col1=data_tfidf.getcol(c1).nonzero()\n",
    "            col2=data_tfidf.getcol(c2).nonzero()\n",
    "            #get overlap elements in the two columns, we need them for co-occurrence; columns are words.\n",
    "            #e.g. if both column 1 and column 2 has non-zero values for row k, then we count it as a co-occurrence\n",
    "            #cooccrrence(word_1, word2)=sum of min(data[1,k], data[2,k]) for the overlapping elements\n",
    "            overlap=numpy.intersect1d(col1[0], col2[0]) #overlap elements of column 1 and 2\n",
    "            \n",
    "            coocurr_value=0 #for recording cooccurrence value of word_1 and word_2\n",
    "            \n",
    "            for k in overlap:\n",
    "                elem1=word_doc_matrix.getcol(c1)[k].toarray()[0][0]\n",
    "                elem2=word_doc_matrix.getcol(c2)[k].toarray()[0][0]\n",
    "                \n",
    "                elems=numpy.array([elem1, elem2])\n",
    "                coocurr_value+=numpy.amin(elems)\n",
    "                \n",
    "            cooccurrence_matrix[c1, c2]=coocurr_value\n",
    "            cooccurrence_matrix[c2, c1]=coocurr_value\n",
    "                \n",
    "\n",
    "    return cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-f46b28a50280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcooccurrence_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_cooccur_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-250-474833b96f14>\u001b[0m in \u001b[0;36mbuild_cooccur_matrix\u001b[1;34m(word_doc_matrix)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moverlap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0melem1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_doc_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0melem2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_doc_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0melems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Miao\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mgetcol\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mCSR\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_row_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Miao\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[1;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[0;32m    422\u001b[0m         indptr, indices, data = get_csr_submatrix(M, N,\n\u001b[0;32m    423\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 int(i0), int(i1), int(j0), int(j1))\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mj0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cooccurrence_matrix=build_cooccur_matrix(data[0])\n",
    "###it's taking too long, so aborted the program, it will be a 204562*204562 matrix..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we obtain doc similiarity based on word vectors from word_doc matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028306925853614828"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx1=word_index_hash['hlstory']\n",
    "idx2=word_index_hash['historv']\n",
    "\n",
    "docvec1=data[0].getcol(idx1).toarray()\n",
    "docvec2=data[0].getcol(idx2).toarray()\n",
    "\n",
    "1-cosine(docvec1, docvec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#given 2 words, calculate their similarity based on in what document they occur\n",
    "#a word's vector here is all the documents it has occurred, can be obtained from word_doc matrix\n",
    "def wordSimilarityBasedOnDocVec(word_doc_matrix, w1, w2):\n",
    "    idx1=word_index_hash[w1]\n",
    "    idx2=word_index_hash[w2]\n",
    "    \n",
    "    docvec1=word_doc_matrix.getcol(idx1).toarray()\n",
    "    docvec2=word_doc_matrix.getcol(idx2).toarray()\n",
    "    \n",
    "    return 1-cosine(docvec1, docvec2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028306925853614828"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSimilarityBasedOnDocVec(data[0], 'hlstory', 'historv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0283069258536\n",
      "0.0\n",
      "0.078072600677\n",
      "0.0267049381997\n"
     ]
    }
   ],
   "source": [
    "print wordSimilarityBasedOnDocVec(data[0], 'hlstory', 'historv')\n",
    "print wordSimilarityBasedOnDocVec(data[0], 'himselt', 'himself')\n",
    "print wordSimilarityBasedOnDocVec(data[0], 'historv', 'riage')\n",
    "print wordSimilarityBasedOnDocVec(data[0], 'himselt', 'riage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering on document-word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=20, init='k-means++', max_iter=100, n_init=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 1976681818.000\n",
      "Iteration  1, inertia 1659199417.779\n",
      "Iteration  2, inertia 1637356293.531\n",
      "Iteration  3, inertia 1622846354.323\n",
      "Iteration  4, inertia 1620377879.539\n",
      "Iteration  5, inertia 1619919276.548\n",
      "Iteration  6, inertia 1619091789.334\n",
      "Converged at iteration 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=20, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.383\n"
     ]
    }
   ],
   "source": [
    "#The Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. \n",
    "#The Silhouette Coefficient for a sample is (b - a) / max(a, b).\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(data[0], km.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get Silhouette coefficient for clustering result\n",
    "def clusterAndGetSilhouetteCoef(data, n_clusters):\n",
    "    km = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
    "    km.fit(data)\n",
    "    return metrics.silhouette_score(data, km.labels_, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 2406258056.000\n",
      "Iteration  1, inertia 2101185834.829\n",
      "Iteration  2, inertia 2075810706.425\n",
      "Iteration  3, inertia 2074197054.718\n",
      "Converged at iteration 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5402546431251406"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51279720911233428"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 1546426139.000\n",
      "Iteration  1, inertia 1354477239.732\n",
      "Iteration  2, inertia 1337592291.058\n",
      "Iteration  3, inertia 1331814707.011\n",
      "Iteration  4, inertia 1330332759.597\n",
      "Iteration  5, inertia 1329313686.954\n",
      "Iteration  6, inertia 1328518836.208\n",
      "Iteration  7, inertia 1326682477.368\n",
      "Iteration  8, inertia 1325773063.771\n",
      "Iteration  9, inertia 1325468017.089\n",
      "Iteration 10, inertia 1325335156.650\n",
      "Converged at iteration 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40445106004206155"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 1361518178.000\n",
      "Iteration  1, inertia 1137677020.244\n",
      "Iteration  2, inertia 1132849352.343\n",
      "Iteration  3, inertia 1132213222.104\n",
      "Iteration  4, inertia 1131895837.617\n",
      "Iteration  5, inertia 1131676570.271\n",
      "Iteration  6, inertia 1131287160.464\n",
      "Iteration  7, inertia 1131191866.664\n",
      "Iteration  8, inertia 1131056782.105\n",
      "Iteration  9, inertia 1130978265.743\n",
      "Iteration 10, inertia 1130927283.870\n",
      "Iteration 11, inertia 1130917454.399\n",
      "Iteration 12, inertia 1130907031.260\n",
      "Converged at iteration 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31384905403882807"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 1141417253.000\n",
      "Iteration  1, inertia 980731217.669\n",
      "Iteration  2, inertia 968114113.748\n",
      "Iteration  3, inertia 965543659.458\n",
      "Iteration  4, inertia 964273837.305\n",
      "Iteration  5, inertia 963687455.162\n",
      "Iteration  6, inertia 963331209.030\n",
      "Iteration  7, inertia 963090235.364\n",
      "Iteration  8, inertia 963062570.900\n",
      "Iteration  9, inertia 963047181.214\n",
      "Converged at iteration 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20205560562056302"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 947417017.000\n",
      "Iteration  1, inertia 808947545.414\n",
      "Iteration  2, inertia 800440967.529\n",
      "Iteration  3, inertia 797283170.537\n",
      "Iteration  4, inertia 796356260.842\n",
      "Iteration  5, inertia 795859859.282\n",
      "Iteration  6, inertia 795827544.279\n",
      "Converged at iteration 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2376479235768805"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 832628555.000\n",
      "Iteration  1, inertia 724360598.469\n",
      "Iteration  2, inertia 721435682.275\n",
      "Iteration  3, inertia 720989138.145\n",
      "Iteration  4, inertia 720807103.989\n",
      "Iteration  5, inertia 720757145.191\n",
      "Iteration  6, inertia 720639065.315\n",
      "Iteration  7, inertia 720470453.841\n",
      "Iteration  8, inertia 720260263.794\n",
      "Iteration  9, inertia 720124624.594\n",
      "Iteration 10, inertia 720055755.536\n",
      "Iteration 11, inertia 719979689.899\n",
      "Iteration 12, inertia 719932347.294\n",
      "Iteration 13, inertia 719906567.070\n",
      "Converged at iteration 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29433449920150867"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 775156687.000\n",
      "Iteration  1, inertia 659042679.980\n",
      "Iteration  2, inertia 653541301.157\n",
      "Iteration  3, inertia 650857129.815\n",
      "Iteration  4, inertia 648534500.152\n",
      "Iteration  5, inertia 647583424.446\n",
      "Iteration  6, inertia 646560412.673\n",
      "Iteration  7, inertia 646010935.863\n",
      "Iteration  8, inertia 645764041.820\n",
      "Iteration  9, inertia 645526711.843\n",
      "Converged at iteration 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28041505608648298"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 685373957.000\n",
      "Iteration  1, inertia 574222683.964\n",
      "Iteration  2, inertia 569952328.178\n",
      "Iteration  3, inertia 565919318.445\n",
      "Iteration  4, inertia 563780154.580\n",
      "Iteration  5, inertia 562720409.652\n",
      "Iteration  6, inertia 562332256.911\n",
      "Iteration  7, inertia 562142877.081\n",
      "Converged at iteration 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27975255923038717"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 649516530.000\n",
      "Iteration  1, inertia 532540042.201\n",
      "Iteration  2, inertia 527733582.321\n",
      "Iteration  3, inertia 526038370.499\n",
      "Iteration  4, inertia 524576045.795\n",
      "Iteration  5, inertia 523109113.399\n",
      "Iteration  6, inertia 522740728.256\n",
      "Iteration  7, inertia 522648306.857\n",
      "Iteration  8, inertia 522576551.891\n",
      "Iteration  9, inertia 522408678.989\n",
      "Iteration 10, inertia 522369000.972\n",
      "Converged at iteration 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28598567057044871"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterAndGetSilhouetteCoef(data[0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593L, 2L)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km_onPC = KMeans(n_clusters=20, init='k-means++', max_iter=100, n_init=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 13139122.916\n",
      "Iteration  1, inertia 10852053.894\n",
      "Iteration  2, inertia 10499448.498\n",
      "Iteration  3, inertia 10389777.925\n",
      "Iteration  4, inertia 10256363.453\n",
      "Iteration  5, inertia 10031508.548\n",
      "Iteration  6, inertia 9864388.466\n",
      "Iteration  7, inertia 9761203.441\n",
      "Iteration  8, inertia 9701866.007\n",
      "Iteration  9, inertia 9662486.596\n",
      "Iteration 10, inertia 9627938.711\n",
      "Iteration 11, inertia 9598416.772\n",
      "Iteration 12, inertia 9573832.586\n",
      "Converged at iteration 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=20, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_onPC.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: -0.116\n"
     ]
    }
   ],
   "source": [
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(data[0], km_onPC.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 204562)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86129"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2=word_index_hash['historv']\n",
    "idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
